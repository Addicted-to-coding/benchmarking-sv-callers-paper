{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import sys\n",
    " \n",
    "    \n",
    "length_gold=[]    \n",
    "    \n",
    "f = open('../gold_standard/mouse_vcf/AKR_J_reference.vcf')\n",
    "reader = csv.reader(f,delimiter='\\t')\n",
    "for row in reader:\n",
    "    if \"#\" not in row[0]:\n",
    "        l=int(row[1])\n",
    "        length_gold.append(l)\n",
    "f.close()\n",
    "\n",
    "print (len(length_gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strain-specific: 136\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "strain=['AKR_J','A_J','BALB_CJ','C3H_HeJ','CBA_J','DBA_2J','LP_J']\n",
    "\n",
    "dict={}\n",
    "\n",
    "\n",
    "for s in strain:\n",
    "    dict[s]=set()\n",
    "\n",
    "for s in strain:\n",
    "    f = open('../gold_standard/mouse_vcf/'+s+'_reference.vcf')\n",
    "    reader = csv.reader(f,delimiter='\\t')\n",
    "    for row in reader:\n",
    "        if \"#\" not in row[0]:\n",
    "            x=row[1]\n",
    "            y=row[7].split('END=')[1]\n",
    "            #print x,y\n",
    "            dict[s].add(int(x+y))\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "del_list=[]\n",
    "\n",
    "for s in strain:\n",
    "    del_list+=(dict[s])\n",
    "    \n",
    "\n",
    "Counter(del_list)\n",
    "\n",
    "dict_count={}\n",
    "for i in range(1,8):\n",
    "    dict_count[i]=0\n",
    "\n",
    "\n",
    "fileOut=open('../analysis_files/deletions.7.strains.across.samples.csv','w')\n",
    "fileOut.write('del,n_strain\\n')\n",
    "\n",
    "\n",
    "for key, value in Counter(del_list).items():\n",
    "    dict_count[value]+=1\n",
    "\n",
    "        \n",
    "    fileOut.write(str(key)+\",\"+str(value))\n",
    "    fileOut.write(\"\\n\")\n",
    "    \n",
    "    \n",
    "fileOut.close()\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "fileOut=open('../analysis_files/deletions.7.strains.summary.csv','w')\n",
    "fileOut.write('n_del,n_strain\\n')\n",
    "for key, value in dict_count.items():\n",
    "    fileOut.write(str(key)+\",\"+str(value))\n",
    "    fileOut.write(\"\\n\")\n",
    "fileOut.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"strain-specific:\", dict_count[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x10b2dc9d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('../analysis_files/deletions.7.strains.across.samples.csv')\n",
    "\n",
    "data.head()\n",
    "\n",
    "\n",
    "\n",
    "g=sns.set_style(\"white\")\n",
    "g=sns.set_context(\"talk\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "g=sns.catplot(x=\"n_strain\", kind=\"count\", palette=\"ch:.25\", data=data)\n",
    "g.set_axis_labels(\"Number of strains deletion was present\", \"Number of deletions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length of Deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3710\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "strain=['AKR_J','A_J','BALB_CJ','C3H_HeJ','CBA_J','DBA_2J','LP_J']\n",
    "\n",
    "\n",
    "dict_length={}\n",
    "\n",
    "\n",
    "\n",
    "fileOut=open('../analysis_files/deletions.7.strains.length.csv','w')\n",
    "fileOut.write('strain,len,n_true\\n')\n",
    "count=0\n",
    "for s in strain:\n",
    "    f = open('../gold_standard/mouse_vcf/'+s+'_reference.vcf')\n",
    "    reader = csv.reader(f,delimiter='\\t')\n",
    "    for row in reader:\n",
    "        if \"#\" not in row[0]:\n",
    "            l=row[7].split('SVLEN=')[1].split(\";\")[0]\n",
    "            x = int(l)\n",
    "            \n",
    "            if x >= 50:\n",
    "                if x >= 50 and x < 100:\n",
    "                    l=\"50-100\"\n",
    "                elif x >= 100 and x < 500:\n",
    "                    l=\"100-500\"\n",
    "                elif x >= 500 and x < 1000:\n",
    "                    l=\"500-1000\"\n",
    "                elif x > 1000:\n",
    "                    l=\"1000+\"\n",
    "                \n",
    "                fileOut.write(str(s)+\",\"+str(l)+\",1\")\n",
    "                fileOut.write(\"\\n\")\n",
    "                count+=1\n",
    "    f.close()\n",
    "print(count)\n",
    "    \n",
    "\n",
    "\n",
    "fileOut.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>len</th>\n",
       "      <th>n_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AKR_J</td>\n",
       "      <td>500-1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AKR_J</td>\n",
       "      <td>100-500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AKR_J</td>\n",
       "      <td>100-500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AKR_J</td>\n",
       "      <td>100-500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AKR_J</td>\n",
       "      <td>100-500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  strain       len  n_true\n",
       "0  AKR_J  500-1000       1\n",
       "1  AKR_J   100-500       1\n",
       "2  AKR_J   100-500       1\n",
       "3  AKR_J   100-500       1\n",
       "4  AKR_J   100-500       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_=pd.read_csv('../analysis_files/deletions.7.strains.length.csv')\n",
    "gs_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     strain       len  n_true\n",
      "0     AKR_J   100-500     234\n",
      "1     AKR_J     1000+     140\n",
      "2     AKR_J    50-100      37\n",
      "3     AKR_J  500-1000      83\n",
      "4       A_J   100-500     249\n",
      "5       A_J     1000+     158\n",
      "6       A_J    50-100      37\n",
      "7       A_J  500-1000      74\n",
      "8   BALB_CJ   100-500     260\n",
      "9   BALB_CJ     1000+     157\n",
      "10  BALB_CJ    50-100      37\n",
      "11  BALB_CJ  500-1000      77\n",
      "12  C3H_HeJ   100-500     267\n",
      "13  C3H_HeJ     1000+     149\n",
      "14  C3H_HeJ    50-100      32\n",
      "15  C3H_HeJ  500-1000      80\n",
      "16    CBA_J   100-500     304\n",
      "17    CBA_J     1000+     144\n",
      "18    CBA_J    50-100      38\n",
      "19    CBA_J  500-1000      87\n",
      "20   DBA_2J   100-500     315\n",
      "21   DBA_2J     1000+     149\n",
      "22   DBA_2J    50-100      39\n",
      "23   DBA_2J  500-1000      91\n",
      "24     LP_J   100-500     228\n",
      "25     LP_J     1000+     139\n",
      "26     LP_J    50-100      35\n",
      "27     LP_J  500-1000      70\n"
     ]
    }
   ],
   "source": [
    "gs_ = gs_.groupby(['strain','len'])['n_true'].sum().reset_index()\n",
    "print(gs_)\n",
    "gs_.to_csv('../gold_standard/gs_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
